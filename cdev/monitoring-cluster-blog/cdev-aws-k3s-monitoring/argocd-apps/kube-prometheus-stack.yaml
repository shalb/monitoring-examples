apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: monitoring
  namespace: argocd
spec:
  destination:
    namespace: monitoring
    server: https://kubernetes.default.svc
  project: default
  source:
    repoURL: https://prometheus-community.github.io/helm-charts
    chart: kube-prometheus-stack
    targetRevision: 35.0.3
    helm:
      skipCrds: true
      values: |
        # CRDs created by this chart are not removed by default and should be manually cleaned up:
        # https://github.com/prometheus-community/helm-charts/tree/main/charts/kube-prometheus-stack#uninstall-helm-chart

        #kubeControllerManager:
        #  enabled: false


        #kubeScheduler:
        #  enabled: false


        prometheusOperator:
          admissionWebhooks:
            enabled: false
          tls:
            enabled: false


        nodeExporter:
          serviceMonitor:
            relabelings:
              - sourceLabels: [__meta_kubernetes_endpoint_node_name]
                targetLabel: node


        #kubeDns:
        #  enabled: true


        #coreDns:
        #  enabled: false


        grafana:
          adminPassword: admin
          #adminPassword: {{ .variables.grafana_password }}
          #adminPassword: {{ .project.variables.grafana_password }}

          # Enable google auth if needed
          #env:
          #  GF_SERVER_ROOT_URL: "https://grafana.example.local.lan"
          #  GF_AUTH_GOOGLE_ENABLED: "true"
          #  GF_AUTH_GOOGLE_CLIENT_ID: "exampleID"
          #  GF_AUTH_GOOGLE_CLIENT_SECRET: "exampleSecret"
          #  GF_AUTH_GOOGLE_ALLOWED_DOMAINS: "example-1.local.lan example-2.local.lan"
          #  GF_AUTH_GOOGLE_ALLOW_SIGN_UP: "true"

          # Enable ingress if needed
          ingress:
            enabled: false
            annotations:                                                           
              cert-manager.io/cluster-issuer: letsencrypt-prod
              kubernetes.io/ingress: map[class:nginx] 
              kubernetes.io/tls-acme: "true"                                       
              nginx.ingress.kubernetes.io/backend-protocol: HTTP
              #nginx.ingress.kubernetes.io/backend-protocol: HTTPS
              #nginx.ingress.kubernetes.io/ssl-passthrough: "true"
          #  annotations:
          #    cert-manager.io/cluster-issuer: letsencrypt-prod
          #    ingress.kubernetes.io/ssl-redirect: "true"
          #    kubernetes.io/ingress.class: "nginx"
          #    kubernetes.io/tls-acme: "true"
            path: /
            hosts:
              - grafana.{{ .variables.cluster_name }}.{{ .variables.domain }}
            tls:
            - hosts:
              - grafana.{{ .variables.cluster_name }}.{{ .variables.domain }}
              secretName: grafana-tls-secret

          #grafana.ini:
          #  server:
          #    root_url: https://grafana.{{ .variables.cluster_name }}.{{ .variables.domain }}

          # Enable persistant storage if needed
          #persistence:
          #  enabled: true
          #  size: 5Gi
          #additionalDataSources:
          #  - name: prometheus-dev
          #    type: prometheus
          #    url: https://prometheus-dev.example.local.lan
          #    basicAuth: true
          #    basicAuthUser: admin
          #    basicAuthPassword: examplePasswordDev
          #    editable: true
          #    version: 3


        prometheus:
          # Enable ingress if needed
          #ingress:
          #  enabled: true
          #  annotations:
          #    cert-manager.io/cluster-issuer: letsencrypt-prod
          #    nginx.ingress.kubernetes.io/auth-type: basic
          #    nginx.ingress.kubernetes.io/auth-secret: prometheus-basic-auth
          #    nginx.ingress.kubernetes.io/auth-realm: "Authentication Required"
          #    ingress.kubernetes.io/ssl-redirect: "true"
          #    kubernetes.io/ingress.class: "nginx"
          #    kubernetes.io/tls-acme: "true"
          #  hosts:
          #    - prometheus.{{ .variables.cluster_name }}.{{ .variables.domain }}
          #  paths:
          #    - /
          #  tls:
          #    - secretName: prometheus-tls
          #      hosts:
          #        - prometheus.{{ .variables.cluster_name }}.{{ .variables.domain }}

          prometheusSpec:
            serviceMonitorSelectorNilUsesHelmValues: false
            podMonitorSelectorNilUsesHelmValues: false
            probeSelectorNilUsesHelmValues: false
            ruleSelectorNilUsesHelmValues: false

            externalLabels:
              cluster_name: {{ .variables.cluster_name }}
              env: {{ .variables.env }}
              organization: {{ .variables.organization }}
              region: {{ .variables.region }}
              domain: {{ .variables.domain }}

            #externalUrl: https://prometheus.{{ .variables.cluster_name }}.{{ .variables.domain }}
            #retention: 30d

            # Enable persistant storage if needed
            #storageSpec:
            #  volumeClaimTemplate:
            #    spec:
            #      accessModes: ["ReadWriteOnce"]
            #      resources:
            #        requests:
            #          storage: 50Gi


        alertmanager:
          # Enable ingress if needed
          #ingress:
          #  enabled: true
          #  annotations:
          #    cert-manager.io/cluster-issuer: letsencrypt-prod
          #    nginx.ingress.kubernetes.io/auth-type: basic
          #    nginx.ingress.kubernetes.io/auth-secret: prometheus-basic-auth
          #    nginx.ingress.kubernetes.io/auth-realm: "Authentication Required"
          #    ingress.kubernetes.io/ssl-redirect: "true"
          #    kubernetes.io/ingress.class: "nginx"
          #    kubernetes.io/tls-acme: "true"
          #  hosts:
          #    - alertmanager.{{ .variables.cluster_name }}.{{ .variables.domain }}
          #  paths:
          #    - /
          #  tls:
          #    - secretName: alertmanager-tls
          #      hosts:
          #        - alertmanager.{{ .variables.cluster_name }}.{{ .variables.domain }}

          #alertmanagerSpec:
            #externalUrl: https://alertmanager.{{ .variables.cluster_name }}.{{ .variables.domain }}
            # Enable persistant storage if needed
            #storage:
            #  volumeClaimTemplate:
            #    spec:
            #      accessModes: ["ReadWriteOnce"]
            #      resources:
            #        requests:
            #          storage: 1Gi

          config:
            global:
              resolve_timeout: 5m
            route:
              group_by: [...]
              group_wait: 9s
              group_interval: 9s
              repeat_interval: 120h
              receiver: blackhole
              routes:
              # Alerting disabled - enable only for prod
              - receiver: blackhole
                group_by: [...]
                repeat_interval: 120h

              #- receiver: customer_slack
              #  group_by: [...]
              #  continue: true
              #  repeat_interval: 120h

              # Non needed alerts disabled
              #- receiver: blackhole
              #  group_by: [...]
              #  match_re:
              #    alertname: "CPUThrottlingHigh"
              #  repeat_interval: 120h

              - receiver: opsgenie_info
                group_by: [...]
                match_re:
                  severity: "info"
                continue: true
                repeat_interval: 120h

              - receiver: opsgenie_warning
                group_by: [...]
                match_re:
                  severity: "warning"
                continue: true
                repeat_interval: 120h

              - receiver: opsgenie_critical
                group_by: [...]
                match_re:
                  severity: "critical"
                continue: true
                repeat_interval: 120h

            receivers:
            - name: blackhole

            - name: opsgenie_critical
              opsgenie_configs:
                - api_key: exampleAPIKey
                  responders:
                    - name: exampleTeam
                      type: team
                  message: "{{ .GroupLabels.cluster_name }} | {{ .GroupLabels.alertname }} {{ .CommonAnnotations.message }}"
                  priority: "P1"

            - name: opsgenie_warning
              opsgenie_configs:
                - api_key: exampleAPIKey
                  responders:
                    - name: exampleTeam
                      type: team
                  message: "{{ .GroupLabels.cluster_name }} | {{ .GroupLabels.alertname }} {{ .CommonAnnotations.message }}"
                  priority: "P3"

            - name: opsgenie_info
              opsgenie_configs:
                - api_key: exampleAPIKey
                  responders:
                    - name: exampleTeam
                      type: team
                  message: "{{ .GroupLabels.cluster_name }} | {{ .GroupLabels.alertname }} {{ .CommonAnnotations.message }}"
                  priority: "P5"

            #- name: customer_slack
            #  slack_configs:
            #    - api_url: https://hooks.slack.com/services/000000000/00000000000/000000000000000000000000
            #      username: prometheus
            #      title: "cluster_name: '{{ .GroupLabels.cluster_name }}' | alert: '{{ .GroupLabels.alertname }} {{ .CommonAnnotations.message }}'"
            #      text: "{{ .CommonAnnotations.description }}"
            #      title_link: "https://grafana.{{ .variables.cluster_name }}.{{ .variables.domain }}/{{ .CommonAnnotations.grafana_title_link }}"
            #      send_resolved: true
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    syncOptions:
    - CreateNamespace=true
